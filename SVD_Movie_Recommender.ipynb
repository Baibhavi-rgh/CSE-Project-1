{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baibhavi-rgh/CSE-Project/blob/main/SVD_Movie_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader\n",
        "from surprise import SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "# --- Project Configuration ---\n",
        "# The Surprise library allows loading built-in datasets for quick testing.\n",
        "# We will use the 'ml-100k' dataset (100,000 ratings from 943 users on 1682 movies).\n",
        "DATASET_NAME = 'ml-100k'\n",
        "\n",
        "# --- Helper Function for Top-N Recommendations ---\n",
        "\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"\n",
        "    Returns the top N recommendations for each user from a set of predictions.\n",
        "\n",
        "    :param predictions: The list of predictions (user, item, true_rating, predicted_rating, metadata).\n",
        "    :param n: The number of recommendations to return.\n",
        "    :return: A dictionary mapping user ID to a list of (item ID, predicted rating) tuples.\n",
        "    \"\"\"\n",
        "    # 1. Map the predictions to each user\n",
        "    top_n = {}\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        # Check if the user ID is in the dictionary, if not, initialize it.\n",
        "        if uid not in top_n:\n",
        "            top_n[uid] = []\n",
        "\n",
        "        # Store the item ID and the estimated rating\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # 2. Sort the predictions for each user and retrieve the k highest ones\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        # Sort by predicted rating (est) in descending order\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        # Keep only the top N\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# --- Main Recommender System Logic ---\n",
        "\n",
        "def run_recommender_system():\n",
        "    \"\"\"\n",
        "    Executes the movie recommendation system using the SVD algorithm.\n",
        "    \"\"\"\n",
        "    print(\"--- Movie Recommendation System using SVD (Collaborative Filtering) ---\")\n",
        "\n",
        "    # 1. Load the Dataset\n",
        "    # Load the MovieLens 100k dataset built into the Surprise library.\n",
        "    # This automatically downloads the data if not present.\n",
        "    try:\n",
        "        data = Dataset.load_builtin(DATASET_NAME)\n",
        "        print(f\"Dataset '{DATASET_NAME}' loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. Split Data for Training and Testing\n",
        "    # Split the data into 80% training set and 20% test set for evaluation.\n",
        "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
        "    print(f\"Data split: {len(trainset)} ratings for training, {len(testset)} ratings for testing.\")\n",
        "\n",
        "    # 3. Initialize and Train the Model (SVD)\n",
        "    # SVD is a Matrix Factorization technique (Model-Based Collaborative Filtering).\n",
        "    # We use default parameters, but these can be tuned (e.g., n_factors, n_epochs).\n",
        "    algo = SVD(random_state=42)\n",
        "    print(\"\\nTraining SVD model...\")\n",
        "    algo.fit(trainset)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # 4. Model Evaluation\n",
        "    # Make predictions on the test set.\n",
        "    predictions = algo.test(testset)\n",
        "\n",
        "    # Compute Root Mean Squared Error (RMSE) to assess prediction accuracy.\n",
        "    # RMSE measures how far off the predicted ratings are from the true ratings.\n",
        "    rmse = accuracy.rmse(predictions, verbose=True)\n",
        "    print(f\"Model Accuracy (RMSE): {rmse:.4f}\")\n",
        "\n",
        "    # 5. Generate Top-N Recommendations for a Sample User\n",
        "\n",
        "    # To get human-readable movie titles, we need the raw data.\n",
        "    # The 'ml-100k' dataset requires manually loading the 'u.item' file for titles.\n",
        "    # We'll use a simplified mapping for demonstration.\n",
        "    # In a real project, you would load the full movie metadata.\n",
        "\n",
        "    # Example: Look up movie titles (simplified for built-in dataset)\n",
        "    # For ml-100k, the movie ID (iid) is an internal ID. We need a mapping.\n",
        "    # Since the built-in loader doesn't give us the item file easily,\n",
        "    # we'll just show the recommended Internal IDs for this runnable demo.\n",
        "\n",
        "    # Find the User-Item rating mapping from the full dataset\n",
        "    full_trainset = data.build_full_trainset()\n",
        "\n",
        "    # Let's pick a sample user ID (e.g., raw user ID '1')\n",
        "    sample_user_id = '1'\n",
        "\n",
        "    # 5a. Identify items the user has NOT rated\n",
        "    all_iids = full_trainset.all_items() # All internal item IDs\n",
        "    rated_iids = {iid for (iid, _) in full_trainset.ur[full_trainset.to_inner_uid(sample_user_id)]}\n",
        "    unrated_iids = [iid for iid in all_iids if iid not in rated_iids]\n",
        "\n",
        "    # 5b. Predict ratings for unrated items\n",
        "    unrated_predictions = []\n",
        "    for iid in unrated_iids:\n",
        "        # We need the 'raw' item ID, which is the actual movie ID.\n",
        "        raw_iid = full_trainset.to_raw_iid(iid)\n",
        "        # Predict the rating: user_id, movie_id, verbose=False\n",
        "        pred = algo.predict(sample_user_id, raw_iid)\n",
        "        unrated_predictions.append(pred)\n",
        "\n",
        "    # 5c. Get the top 10 recommendations\n",
        "    top_recommendations = get_top_n(unrated_predictions, n=10)\n",
        "\n",
        "    print(f\"\\n--- Top 10 Movie Recommendations for User ID {sample_user_id} ---\")\n",
        "\n",
        "    # top_recommendations is a dictionary, but we only generated for one user.\n",
        "    if sample_user_id in top_recommendations:\n",
        "        rank = 1\n",
        "        for iid, est_rating in top_recommendations[sample_user_id]:\n",
        "            print(f\"Rank {rank}: Movie ID {iid} (Predicted Rating: {est_rating:.3f})\")\n",
        "            rank += 1\n",
        "    else:\n",
        "        print(\"Could not generate recommendations for the sample user.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ensure you have the 'scikit-surprise' and 'pandas' libraries installed:\n",
        "    # pip install scikit-surprise pandas\n",
        "    run_recommender_system()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "f1_0qqahEFWj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}